{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM15GqhFaTAImP29EVhedag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anwarshaik1/ML-Lab-Task-4/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iurU6R9mTx8",
        "outputId": "64bad636-2f7e-400d-92c0-dc6f32f751ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytic Solution:\n",
            "b0: 1.2363636363636363\n",
            "b1: 1.1696969696969697\n",
            "SSE: 5.624242424242423\n",
            "R2: 0.952538038613988\n"
          ]
        }
      ],
      "source": [
        "#Implement Linear Regression and calculate sum of residual error on the followingDatasets.\n",
        "#x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "#y = [1, 3, 2, 5, 7, 8, 8, 9, 10, 12]\n",
        "# Compute the regression coefficients using analytic formulation and calculate SumSquared Error (SSE) and R 2 value.\n",
        "import numpy as np\n",
        "\n",
        "# Define the dataset\n",
        "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
        "\n",
        "# Analytic solution for linear regression\n",
        "def linear_regression_analytic(x, y):\n",
        "    n = len(x)\n",
        "    x_mean = np.mean(x)\n",
        "    y_mean = np.mean(y)\n",
        "\n",
        "    # Compute the coefficients\n",
        "    b1 = np.sum((x - x_mean) * (y - y_mean)) / np.sum((x - x_mean) ** 2)\n",
        "    b0 = y_mean - b1 * x_mean\n",
        "\n",
        "    # Calculate predicted values\n",
        "    y_pred = b0 + b1 * x\n",
        "\n",
        "    # Calculate SSE\n",
        "    sse = np.sum((y - y_pred) ** 2)\n",
        "\n",
        "    # Calculate R2\n",
        "    ss_total = np.sum((y - y_mean) ** 2)\n",
        "    r2 = 1 - (sse / ss_total)\n",
        "\n",
        "    return b0, b1, sse, r2\n",
        "\n",
        "b0_analytic, b1_analytic, sse_analytic, r2_analytic = linear_regression_analytic(x, y)\n",
        "print(\"Analytic Solution:\")\n",
        "print(\"b0:\", b0_analytic)\n",
        "print(\"b1:\", b1_analytic)\n",
        "print(\"SSE:\", sse_analytic)\n",
        "print(\"R2:\", r2_analytic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement gradient descent (both Full-batch and Stochastic with stoppingcriteria) on Least Mean Square loss formulation to compute the coefficients ofregression matrix and compare the results using performance measures such as R 2SSE etc.\n",
        "# Gradient Descent for Linear Regression\n",
        "\n",
        "def gradient_descent(x, y, learning_rate=0.001, epochs=1000, batch_size=None):\n",
        "    n = len(x)\n",
        "    b0 = 0\n",
        "    b1 = 0\n",
        "    sse_list = []\n",
        "    r2_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        y_pred = b0 + b1 * x\n",
        "\n",
        "        # Compute gradients\n",
        "        db0 = (1/n) * np.sum(y_pred - y)\n",
        "        db1 = (1/n) * np.sum((y_pred - y) * x)\n",
        "\n",
        "        # Update coefficients\n",
        "        b0 -= learning_rate * db0\n",
        "        b1 -= learning_rate * db1\n",
        "\n",
        "        # Calculate SSE\n",
        "        sse = np.sum((y - y_pred) ** 2)\n",
        "        sse_list.append(sse)\n",
        "\n",
        "        # Calculate R2\n",
        "        ss_total = np.sum((y - np.mean(y)) ** 2)\n",
        "        r2 = 1 - (sse / ss_total)\n",
        "        r2_list.append(r2)\n",
        "\n",
        "        # Stopping criteria: SSE doesn't change much\n",
        "        if len(sse_list) > 1 and np.abs(sse_list[-1] - sse_list[-2]) < 1e-6:\n",
        "            break\n",
        "\n",
        "    return b0, b1, sse_list[-1], r2_list[-1]\n",
        "\n",
        "# Full-batch Gradient Descent\n",
        "b0_batch, b1_batch, sse_batch, r2_batch = gradient_descent(x, y)\n",
        "print(\"\\nFull-batch Gradient Descent:\")\n",
        "print(\"b0:\", b0_batch)\n",
        "print(\"b1:\", b1_batch)\n",
        "print(\"SSE:\", sse_batch)\n",
        "print(\"R2:\", r2_batch)\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def stochastic_gradient_descent(x, y, learning_rate=0.001, epochs=1000):\n",
        "    n = len(x)\n",
        "    b0 = 0\n",
        "    b1 = 0\n",
        "    sse_list = []\n",
        "    r2_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(n):\n",
        "            y_pred = b0 + b1 * x[i]\n",
        "\n",
        "            # Compute gradients\n",
        "            db0 = y_pred - y[i]\n",
        "            db1 = (y_pred - y[i]) * x[i]\n",
        "\n",
        "            # Update coefficients\n",
        "            b0 -= learning_rate * db0\n",
        "            b1 -= learning_rate * db1\n",
        "\n",
        "        # Calculate SSE\n",
        "        sse = np.sum((y - (b0 + b1 * x)) ** 2)\n",
        "        sse_list.append(sse)\n",
        "\n",
        "        # Calculate R2\n",
        "        ss_total = np.sum((y - np.mean(y)) ** 2)\n",
        "        r2 = 1 - (sse / ss_total)\n",
        "        r2_list.append(r2)\n",
        "\n",
        "        # Stopping criteria: SSE doesn't change much\n",
        "        if len(sse_list) > 1 and np.abs(sse_list[-1] - sse_list[-2]) < 1e-6:\n",
        "            break\n",
        "\n",
        "    return b0, b1, sse_list[-1], r2_list[-1]\n",
        "\n",
        "b0_stochastic, b1_stochastic, sse_stochastic, r2_stochastic = stochastic_gradient_descent(x, y)\n",
        "print(\"\\nStochastic Gradient Descent:\")\n",
        "print(\"b0:\", b0_stochastic)\n",
        "print(\"b1:\", b1_stochastic)\n",
        "print(\"SSE:\", sse_stochastic)\n",
        "print(\"R2:\", r2_stochastic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTnXrg-fnT1o",
        "outputId": "9e0cff8f-8cb5-4bc0-ba30-46cbb39684d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full-batch Gradient Descent:\n",
            "b0: 0.46445787906819846\n",
            "b1: 1.2927964338533071\n",
            "SSE: 7.3504366896211994\n",
            "R2: 0.9379709983998211\n",
            "\n",
            "Stochastic Gradient Descent:\n",
            "b0: 1.1770816715547667\n",
            "b1: 1.1770770892948816\n",
            "SSE: 5.635533075737099\n",
            "R2: 0.9524427588545392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download Boston Housing Rate Dataset. Analyse the input attributes and find out theattribute that best follow the linear relationship with the output price. Implement both the\n",
        "#analytic formulation and gradient descent (Full-batch, stochastic) on LMS lossformulation to compute the coefficients of regression matrix and compare the results.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing_data = pd.read_csv(\"/content/housing (3).csv\")\n",
        "\n",
        "selected_attribute = 'median_income'\n",
        "X = housing_data[selected_attribute].values.reshape(-1, 1)\n",
        "y = housing_data['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_with_intercept = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test_with_intercept = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "theta_analytic = np.linalg.inv(X_train_with_intercept.T.dot(X_train_with_intercept)).dot(X_train_with_intercept.T).dot(y_train)\n",
        "print(\"Coefficients using Analytic Formulation:\", theta_analytic)\n",
        "\n",
        "def full_batch_gradient_descent(X, y, learning_rate, num_iterations):\n",
        "    theta = np.zeros(X.shape[1])\n",
        "    for _ in range(num_iterations):\n",
        "        y_pred = X.dot(theta)\n",
        "        theta -= (1/len(y)) * learning_rate * X.T.dot(y_pred - y)\n",
        "    return theta\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "theta_full_batch = full_batch_gradient_descent(X_train_with_intercept, y_train, learning_rate, num_iterations)\n",
        "print(\"Coefficients using Full-batch Gradient Descent:\", theta_full_batch)\n",
        "\n",
        "def stochastic_gradient_descent(X, y, learning_rate, num_iterations):\n",
        "    theta = np.zeros(X.shape[1])\n",
        "    m = len(y)  # Number of training examples\n",
        "\n",
        "    # Shuffle the training data once before training\n",
        "    shuffle_index = np.random.permutation(len(y))\n",
        "    X_shuffled = X[shuffle_index]\n",
        "    y_shuffled = y[shuffle_index]\n",
        "\n",
        "    # SGD loop\n",
        "    for _ in range(num_iterations):\n",
        "        for xi, yi in zip(X_shuffled, y_shuffled):\n",
        "            y_pred = np.dot(xi, theta)\n",
        "            gradient = xi * (y_pred - yi)\n",
        "            theta -= learning_rate * gradient\n",
        "\n",
        "    return theta\n",
        "\n",
        "theta_stochastic = stochastic_gradient_descent(X_train_with_intercept, y_train, learning_rate, num_iterations)\n",
        "print(\"Coefficients using Stochastic Gradient Descent:\", theta_stochastic)\n",
        "# Predictions\n",
        "y_pred_analytic = X_test_with_intercept.dot(theta_analytic)\n",
        "y_pred_full_batch = X_test_with_intercept.dot(theta_full_batch)\n",
        "y_pred_stochastic = X_test_with_intercept.dot(theta_stochastic)\n",
        "\n",
        "# Calculate SSE\n",
        "SSE_analytic = np.sum((y_test - y_pred_analytic) ** 2)\n",
        "SSE_full_batch = np.sum((y_test - y_pred_full_batch) ** 2)\n",
        "SSE_stochastic = np.sum((y_test - y_pred_stochastic) ** 2)\n",
        "\n",
        "# Calculate total sum of squares (SST)\n",
        "mean_y = np.mean(y_test)\n",
        "SST = np.sum((y_test - mean_y) ** 2)\n",
        "\n",
        "# Calculate R-squared\n",
        "R_squared_analytic = 1 - (SSE_analytic / SST)\n",
        "R_squared_full_batch = 1 - (SSE_full_batch / SST)\n",
        "R_squared_stochastic = 1 - (SSE_stochastic / SST)\n",
        "\n",
        "print(\"SSE and R-squared value:\")\n",
        "print(\"Analytic Formulation: SSE =\", SSE_analytic, \", R-squared =\", R_squared_analytic)\n",
        "print(\"Full-batch Gradient Descent: SSE =\", SSE_full_batch, \", R-squared =\", R_squared_full_batch)\n",
        "print(\"Stochastic Gradient Descent: SSE =\", SSE_stochastic, \", R-squared =\", R_squared_stochastic)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "hikm8FIZpkVP",
        "outputId": "11004832-49e1-4014-984e-fa8d547f8cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/housing (3).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7d1e2ad0e577>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhousing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/housing (3).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mselected_attribute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'median_income'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/housing (3).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZunXO3G0qK6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}